{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf51547e-96f9-4976-bd27-21eeb1c9e104",
   "metadata": {},
   "source": [
    "### MobileNet model transfer learning: 86 layers + 12 additional layers (fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ec121d-074d-459f-bfea-e17b607201b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64928aca-3a4b-4135-ae0a-e817cbc6eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the global policy to mixed_float16\n",
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6f089-6c9f-43e1-bbc9-ca433b4e3df3",
   "metadata": {},
   "source": [
    "### Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9abc40-2456-4900-abb4-9ec535371466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the script uses the GPU if available and set memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set at program startup\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5236c0-e349-47b4-9635-c72ef1c87947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your preprocessed data\n",
    "X_train = np.load('X_train-s.npy')\n",
    "X_val = np.load('X_val-s.npy')\n",
    "y_train = np.load('y_train-s.npy')\n",
    "y_val = np.load('y_val-s.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a59448-6c8a-4473-9e7e-4996f16ff9d1",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc68cf6-5bc7-40e3-8ab3-8940b50a4987",
   "metadata": {},
   "source": [
    "- Include Dropout Layers: These layers will help prevent overfitting.\n",
    "- Add Additional Convolutional Layers: This will allow the model to learn more complex features.\n",
    "- Enable Fine-Tuning: Allow for the fine-tuning of more layers during the training process.\n",
    "- Add Regularization to Dense Layers: This will help in avoiding overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726522ee-d6ef-4fcd-bb09-e1bf11780f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenet_model(hp):\n",
    "    # Hyperparameters\n",
    "    freeze_layers = hp.Int('freeze_layers', min_value=0, max_value=20, step=5)\n",
    "    dense_units = hp.Int('dense_units', min_value=32, max_value=128, step=16)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    l2_reg = hp.Float('l2_reg', min_value=1e-5, max_value=1e-2, step=1e-5)\n",
    "\n",
    "    # MobileNet base model\n",
    "    image_input = Input(shape=(224, 224, 3))\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "    print(\"Initial number of layers in the base model:\", len(base_model.layers))\n",
    "\n",
    "    # Freeze the initial layers for finetuning\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Custom layers on top of MobileNet\n",
    "    x = base_model.output\n",
    "\n",
    "    # Additional Convolutional Layers\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Flatten the output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dense(dense_units, activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(26, activation='softmax')(x)  # 26 classes for A-Z\n",
    "\n",
    "    model = Model(inputs=image_input, outputs=x)\n",
    "    print(\"Total number of layers in the model:\", len(model.layers))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6533e1-2b1c-49a6-8c85-39d2f27c0d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from mobilenet-model-tuning/mobilenet-tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "\n",
    "# Set up the tuner for hyperparameter tuning using Hyperband\n",
    "tuner = kt.Hyperband(\n",
    "    build_mobilenet_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=2,  # Number of times to iterate over the full Hyperband algorithm\n",
    "    directory='mobilenet-model-tuning',\n",
    "    project_name='mobilenet-tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0bbc0-67a5-4778-b535-25e1d7cbe6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bffd4123-6809-4e59-a15d-43aeead31e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze_layers: 15\n",
      "dense_units: 64\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "l2_reg: 0.00595\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Print each hyperparameter and its corresponding best value\n",
    "for hp in best_hp.space:\n",
    "    print(f\"{hp.name}: {best_hp.get(hp.name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d6e167-2541-41d5-9a0a-603da88ac3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all completed trials\n",
    "trials = [t for t in tuner.oracle.trials.values() if t.status == 'COMPLETED']\n",
    "\n",
    "# Prepare data for CSV\n",
    "data_to_save = [[\"Trial Number\", \"Hyperparameters\", \"Validation Accuracy\"]]\n",
    "\n",
    "# Add data from each trial\n",
    "for i, trial in enumerate(trials):\n",
    "    trial_hyperparams = trial.hyperparameters.values\n",
    "    val_accuracy = trial.score  \n",
    "    data_to_save.append([f\"Trial {i+1}\", trial_hyperparams, val_accuracy])\n",
    "\n",
    "# Write to CSV\n",
    "with open('hyperparameter_trials.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f4490d9-bde5-48b9-b302-66304540635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 18:44:46.096834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.098791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.100690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.102490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.104666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.106459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.108152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.109830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.111661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.113315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.115156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:46.116874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.376461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.378661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.380793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.382769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.384767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.386658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.388551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.390394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.392241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.394034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13589 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2023-11-14 18:44:48.394485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.396243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13589 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "2023-11-14 18:44:48.397223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.398919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13589 MB memory:  -> device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-11-14 18:44:48.399799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-14 18:44:48.401619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13589 MB memory:  -> device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of layers in the base model: 86\n",
      "Total number of layers in the model: 98\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 18:45:11.931853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/487 [..............................] - ETA: 26s - loss: 5.9995 - accuracy: 0.0312    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 18:45:15.435156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4140004b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-14 18:45:15.435193: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-11-14 18:45:15.435200: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "2023-11-14 18:45:15.435205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5\n",
      "2023-11-14 18:45:15.435211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5\n",
      "2023-11-14 18:45:15.442135: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-14 18:45:15.574885: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - ETA: 0s - loss: 3.6445 - accuracy: 0.1480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 54s 87ms/step - loss: 3.6445 - accuracy: 0.1480 - val_loss: 1.9228 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 1.9892 - accuracy: 0.5379 - val_loss: 0.7502 - val_accuracy: 0.9520 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 1.1472 - accuracy: 0.7975 - val_loss: 0.5114 - val_accuracy: 0.9881 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 0.8008 - accuracy: 0.8982 - val_loss: 0.4510 - val_accuracy: 0.9925 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 0.6415 - accuracy: 0.9390 - val_loss: 0.4111 - val_accuracy: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 0.5365 - accuracy: 0.9607 - val_loss: 0.3822 - val_accuracy: 0.9966 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 0.4653 - accuracy: 0.9731 - val_loss: 0.3531 - val_accuracy: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 0.4086 - accuracy: 0.9801 - val_loss: 0.3132 - val_accuracy: 0.9985 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 0.3612 - accuracy: 0.9845 - val_loss: 0.2805 - val_accuracy: 0.9982 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 32s 66ms/step - loss: 0.3149 - accuracy: 0.9891 - val_loss: 0.2596 - val_accuracy: 0.9964 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_checkpoint = ModelCheckpoint('mobilenet-model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Combine all callbacks\n",
    "callbacks_list = [\n",
    "    LearningRateScheduler(scheduler),\n",
    "    early_stopping,\n",
    "    model_checkpoint\n",
    "]\n",
    "\n",
    "# Train model with best hyperparameters\n",
    "model = build_mobilenet_model(best_hp)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=callbacks_list, verbose=1) # Adjust epochs based on HP << !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d6635-afc5-4801-bd8d-ee2a54b36af7",
   "metadata": {},
   "source": [
    "### Model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802f7bfa-97be-440a-8824-d01d6fe85ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Epoch': range(1, len(history.history['loss']) + 1),\n",
    "    'Loss': history.history['loss'],\n",
    "    'Accuracy': history.history['accuracy'],\n",
    "    'Val_Loss': history.history['val_loss'],\n",
    "    'Val_Accuracy': history.history['val_accuracy'],\n",
    "    'Learning_Rate': history.history['lr']\n",
    "})\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "metrics_df.to_csv('mobilenet-metrics.csv', index=False)\n",
    "\n",
    "# Save full model \n",
    "model.save('mobilenet-fullmodel-full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e539285-5466-4d3a-975c-66b5ed3763f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

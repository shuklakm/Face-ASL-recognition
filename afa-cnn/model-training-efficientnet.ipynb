{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf51547e-96f9-4976-bd27-21eeb1c9e104",
   "metadata": {},
   "source": [
    "### EfficientNet model transfer learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46e431-fed6-43cf-a880-76d5ba30edef",
   "metadata": {},
   "source": [
    "EfficientNetB0 is the baseline model of the EfficientNet family, which consists of a group of convolutional neural networks (CNNs) that were designed to scale more efficiently with respect to the available computational resources. EfficientNetB0 was introduced in a research paper by Mingxing Tan and Quoc V. Le in 2019.\n",
    "\n",
    "EfficientNet models are based on a principle called \"compound scaling,\" where depth, width, and resolution of the network are scaled in a balanced way. The authors of the paper found that scaling up any dimension of a network (depth, width, or resolution) would improve accuracy, but to a certain point. Beyond that point, the network would see diminishing returns in model performance.\n",
    "\n",
    "EfficientNetB0 serves as the baseline for the other EfficientNets (B1-B7), which are scaled up versions of B0 using the compound scaling method. The scaling method multiplies the dimensions of the network by a constant factor, which is determined by a grid search on the baseline B0 model.\n",
    "\n",
    "Key characteristics of EfficientNetB0 include:\n",
    "- It uses a mobile inverted bottleneck convolution (MBConv), similar to MobileNetV2 and MnasNet, which are also designed to be efficient.\n",
    "- It employs squeeze-and-excitation blocks, which allow the network to recalibrate the weights of different channels.\n",
    "- It's optimized to work well across a wide range of input resolutions, making it flexible for different applications.\n",
    "\n",
    "EfficientNets, including B0, achieved state-of-the-art accuracy on ImageNet and other benchmarks at the time of their introduction, while using significantly less compute â€“ hence the name \"EfficientNet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ec121d-074d-459f-bfea-e17b607201b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, Dense, Flatten, concatenate, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import keras_tuner as kt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64928aca-3a4b-4135-ae0a-e817cbc6eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the global policy to mixed_float16\n",
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a0180e-7054-473f-8bef-0ca38fcbb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the script uses the GPU if available and set memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set at program startup\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559507a-d636-422d-85e9-58704dcbb85a",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5236c0-e349-47b4-9635-c72ef1c87947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train loaded\n",
      "X_val loaded\n",
      "y_train loaded\n",
      "y_val loaded\n"
     ]
    }
   ],
   "source": [
    "# Load your preprocessed data\n",
    "X_train = np.load('X_train-299.npy')\n",
    "print('X_train loaded')\n",
    "X_val = np.load('X_val-299.npy')\n",
    "print('X_val loaded')\n",
    "y_train = np.load('y_train-299.npy')\n",
    "print('y_train loaded')\n",
    "y_val = np.load('y_val-299.npy')\n",
    "print('y_val loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a59448-6c8a-4473-9e7e-4996f16ff9d1",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42871f50-31dc-4eaa-9bbc-9ff7097e40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnet_model(hp):\n",
    "    # Load EfficientNetB0 as base model\n",
    "    base_model = EfficientNetB0(include_top=False, input_tensor=Input(shape=(299, 299, 3)), weights='imagenet')\n",
    "    print(\"Initial number of layers in the base model:\", len(base_model.layers))\n",
    "    \n",
    "    # Freeze the base model layers initially\n",
    "    for layer in base_model.layers[:-hp.Int('unfreeze_layers', min_value=0, max_value=len(base_model.layers), step=5)]:\n",
    "        if not isinstance(layer, BatchNormalization):  # It's often advised to keep BatchNormalization layers frozen\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top of EfficientNetB0\n",
    "    x = base_model.output\n",
    "    \n",
    "    # Additional convolutional layers with L2 regularization before the global pooling\n",
    "    for i in range(hp.Int('num_additional_conv_blocks', 1, 3)):\n",
    "        x = Conv2D(filters=hp.Int(f'conv_filters_{i}', min_value=32, max_value=128, step=32),\n",
    "                   kernel_size=hp.Choice(f'conv_kernel_size_{i}', values=[3, 5]),\n",
    "                   activation='relu', padding='same',\n",
    "                   kernel_regularizer=l2(hp.Float(f'conv_l2_reg_{i}', min_value=1e-5, max_value=1e-2, step=1e-5)))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(hp.Float(f'conv_dropout_rate_{i}', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "\n",
    "    # Global pooling layer added after convolutional layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layer with L2 regularization\n",
    "    x = Dense(hp.Int('dense_units', min_value=32, max_value=256, step=32), activation='relu',\n",
    "              kernel_regularizer=l2(hp.Float('dense_l2_reg', min_value=1e-5, max_value=1e-2, step=1e-5)))(x)\n",
    "    x = Dropout(hp.Float('dense_dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    # Output layer\n",
    "    predictions = Dense(26, activation='softmax')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total number of layers in the model:\", len(model.layers))\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdcd86b-b95f-4a2c-941f-1ca1b923b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from efficientnet-model-tuning/efficientnet-tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "\n",
    "# Set up the tuner for hyperparameter tuning using Hyperband\n",
    "tuner = kt.Hyperband(\n",
    "    build_efficientnet_model, \n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=2,  # Number of times to iterate over the full Hyperband algorithm\n",
    "    directory='efficientnet-model-tuning', \n",
    "    project_name='efficientnet-tuning'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e2050a7-9943-4672-8afa-cbf214c027a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 09m 19s]\n",
      "val_accuracy: 0.9654948115348816\n",
      "\n",
      "Best val_accuracy So Far: 0.9934895634651184\n",
      "Total elapsed time: 05h 03m 08s\n"
     ]
    }
   ],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b575cce-5bba-4606-9c97-de85328729ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_additional_conv_blocks: 1\n",
      "conv_filters_0: 96\n",
      "conv_kernel_size_0: 3\n",
      "conv_l2_reg_0: 0.0015400000000000001\n",
      "conv_dropout_rate_0: 0.1\n",
      "dense_units: 160\n",
      "dense_l2_reg: 0.00616\n",
      "dense_dropout_rate: 0.2\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 32\n",
      "conv_kernel_size_1: 5\n",
      "conv_l2_reg_1: 0.00037000000000000005\n",
      "conv_dropout_rate_1: 0.30000000000000004\n",
      "conv_filters_2: 128\n",
      "conv_kernel_size_2: 3\n",
      "conv_l2_reg_2: 0.00337\n",
      "conv_dropout_rate_2: 0.5\n",
      "unfreeze_layers: 215\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Print each hyperparameter and its corresponding best value\n",
    "for hp in best_hp.space:\n",
    "    print(f\"{hp.name}: {best_hp.get(hp.name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee187443-8964-47d3-8d01-0afa36b89e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all completed trials\n",
    "trials = [t for t in tuner.oracle.trials.values() if t.status == 'COMPLETED']\n",
    "\n",
    "# Prepare data for CSV\n",
    "data_to_save = [[\"Trial Number\", \"Hyperparameters\", \"Validation Accuracy\"]]\n",
    "\n",
    "# Add data from each trial\n",
    "for i, trial in enumerate(trials):\n",
    "    trial_hyperparams = trial.hyperparameters.values\n",
    "    val_accuracy = trial.score  \n",
    "    data_to_save.append([f\"Trial {i+1}\", trial_hyperparams, val_accuracy])\n",
    "\n",
    "# Write to CSV\n",
    "with open('efficientnet_hyperparameter_trials.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bae74db-1a6a-49c1-b93d-688a47165b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 12:20:00.625381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.627445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.629393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.631267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.633098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.634851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.636613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.638356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.640024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.641784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.643586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:00.645326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.490680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.492704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.494671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.496658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.498649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.500355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.502068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.503845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.505606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.507402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13589 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2023-11-15 12:20:14.507977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.509749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13589 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "2023-11-15 12:20:14.510104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.511861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13589 MB memory:  -> device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-11-15 12:20:14.512255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-15 12:20:14.513968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13589 MB memory:  -> device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of layers in the base model: 238\n",
      "Total number of layers in the model: 246\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 12:20:58.968674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/195 [..............................] - ETA: 2:14:41 - loss: 4.7920 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 12:21:10.021753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f791800cfa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-15 12:21:10.021799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-11-15 12:21:10.021807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "2023-11-15 12:21:10.021813: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5\n",
      "2023-11-15 12:21:10.021819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5\n",
      "2023-11-15 12:21:10.302956: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-15 12:21:11.040047: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - ETA: 0s - loss: 3.4433 - accuracy: 0.3596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 117s 386ms/step - loss: 3.4433 - accuracy: 0.3596 - val_loss: 4.2254 - val_accuracy: 0.0365 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 55s 281ms/step - loss: 1.9012 - accuracy: 0.8213 - val_loss: 3.4455 - val_accuracy: 0.3177 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 1.3298 - accuracy: 0.9288 - val_loss: 1.3283 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 54s 280ms/step - loss: 1.0895 - accuracy: 0.9647 - val_loss: 0.9537 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.9558 - accuracy: 0.9841 - val_loss: 0.8665 - val_accuracy: 0.9889 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 55s 280ms/step - loss: 0.8732 - accuracy: 0.9865 - val_loss: 0.7976 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.8065 - accuracy: 0.9880 - val_loss: 0.7377 - val_accuracy: 0.9948 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.7349 - accuracy: 0.9918 - val_loss: 0.6819 - val_accuracy: 0.9928 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.6759 - accuracy: 0.9934 - val_loss: 0.6253 - val_accuracy: 0.9954 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.6171 - accuracy: 0.9950 - val_loss: 0.5722 - val_accuracy: 0.9948 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.5636 - accuracy: 0.9952 - val_loss: 0.5319 - val_accuracy: 0.9922 - lr: 9.0484e-05\n",
      "Epoch 12/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.5146 - accuracy: 0.9965 - val_loss: 0.4844 - val_accuracy: 0.9941 - lr: 8.1873e-05\n",
      "Epoch 13/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.4781 - accuracy: 0.9957 - val_loss: 0.4485 - val_accuracy: 0.9961 - lr: 7.4082e-05\n",
      "Epoch 14/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.4372 - accuracy: 0.9976 - val_loss: 0.4194 - val_accuracy: 0.9948 - lr: 6.7032e-05\n",
      "Epoch 15/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.4079 - accuracy: 0.9973 - val_loss: 0.3855 - val_accuracy: 0.9954 - lr: 6.0653e-05\n",
      "Epoch 16/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.3812 - accuracy: 0.9968 - val_loss: 0.3608 - val_accuracy: 0.9961 - lr: 5.4881e-05\n",
      "Epoch 17/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.3557 - accuracy: 0.9978 - val_loss: 0.3375 - val_accuracy: 0.9961 - lr: 4.9659e-05\n",
      "Epoch 18/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.3348 - accuracy: 0.9976 - val_loss: 0.3202 - val_accuracy: 0.9954 - lr: 4.4933e-05\n",
      "Epoch 19/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.3131 - accuracy: 0.9981 - val_loss: 0.2990 - val_accuracy: 0.9974 - lr: 4.0657e-05\n",
      "Epoch 20/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2944 - accuracy: 0.9989 - val_loss: 0.2846 - val_accuracy: 0.9961 - lr: 3.6788e-05\n",
      "Epoch 21/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2809 - accuracy: 0.9986 - val_loss: 0.2671 - val_accuracy: 0.9974 - lr: 3.3287e-05\n",
      "Epoch 22/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2652 - accuracy: 0.9989 - val_loss: 0.2549 - val_accuracy: 0.9974 - lr: 3.0119e-05\n",
      "Epoch 23/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2535 - accuracy: 0.9987 - val_loss: 0.2432 - val_accuracy: 0.9974 - lr: 2.7253e-05\n",
      "Epoch 24/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2423 - accuracy: 0.9987 - val_loss: 0.2348 - val_accuracy: 0.9974 - lr: 2.4660e-05\n",
      "Epoch 25/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2326 - accuracy: 0.9989 - val_loss: 0.2245 - val_accuracy: 0.9961 - lr: 2.2313e-05\n",
      "Epoch 26/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2257 - accuracy: 0.9979 - val_loss: 0.2164 - val_accuracy: 0.9980 - lr: 2.0190e-05\n",
      "Epoch 27/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2158 - accuracy: 0.9990 - val_loss: 0.2087 - val_accuracy: 0.9974 - lr: 1.8268e-05\n",
      "Epoch 28/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.2097 - accuracy: 0.9987 - val_loss: 0.2028 - val_accuracy: 0.9974 - lr: 1.6530e-05\n",
      "Epoch 29/50\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.2019 - accuracy: 0.9998 - val_loss: 0.1965 - val_accuracy: 0.9980 - lr: 1.4957e-05\n",
      "Epoch 30/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1970 - accuracy: 0.9992 - val_loss: 0.1913 - val_accuracy: 0.9974 - lr: 1.3534e-05\n",
      "Epoch 31/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1910 - accuracy: 0.9995 - val_loss: 0.1860 - val_accuracy: 0.9974 - lr: 1.2246e-05\n",
      "Epoch 32/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1867 - accuracy: 0.9990 - val_loss: 0.1804 - val_accuracy: 0.9987 - lr: 1.1080e-05\n",
      "Epoch 33/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1850 - accuracy: 0.9986 - val_loss: 0.1768 - val_accuracy: 0.9980 - lr: 1.0026e-05\n",
      "Epoch 34/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1788 - accuracy: 0.9995 - val_loss: 0.1737 - val_accuracy: 0.9974 - lr: 9.0718e-06\n",
      "Epoch 35/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1770 - accuracy: 0.9990 - val_loss: 0.1708 - val_accuracy: 0.9980 - lr: 8.2085e-06\n",
      "Epoch 36/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1729 - accuracy: 0.9995 - val_loss: 0.1672 - val_accuracy: 0.9987 - lr: 7.4273e-06\n",
      "Epoch 37/50\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.1685 - accuracy: 0.9995 - val_loss: 0.1646 - val_accuracy: 0.9987 - lr: 6.7205e-06\n",
      "Epoch 38/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1666 - accuracy: 0.9995 - val_loss: 0.1627 - val_accuracy: 0.9980 - lr: 6.0810e-06\n",
      "Epoch 39/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1658 - accuracy: 0.9992 - val_loss: 0.1601 - val_accuracy: 0.9987 - lr: 5.5023e-06\n",
      "Epoch 40/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1641 - accuracy: 0.9990 - val_loss: 0.1577 - val_accuracy: 0.9987 - lr: 4.9787e-06\n",
      "Epoch 41/50\n",
      "195/195 [==============================] - 55s 281ms/step - loss: 0.1625 - accuracy: 0.9997 - val_loss: 0.1566 - val_accuracy: 0.9987 - lr: 4.5049e-06\n",
      "Epoch 42/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1601 - accuracy: 0.9994 - val_loss: 0.1560 - val_accuracy: 0.9980 - lr: 4.0762e-06\n",
      "Epoch 43/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1596 - accuracy: 0.9990 - val_loss: 0.1546 - val_accuracy: 0.9987 - lr: 3.6883e-06\n",
      "Epoch 44/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1560 - accuracy: 0.9998 - val_loss: 0.1538 - val_accuracy: 0.9974 - lr: 3.3373e-06\n",
      "Epoch 45/50\n",
      "195/195 [==============================] - 54s 279ms/step - loss: 0.1563 - accuracy: 0.9990 - val_loss: 0.1523 - val_accuracy: 0.9980 - lr: 3.0197e-06\n",
      "Epoch 46/50\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.1546 - accuracy: 0.9994 - val_loss: 0.1511 - val_accuracy: 0.9980 - lr: 2.7324e-06\n",
      "Epoch 47/50\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.1537 - accuracy: 0.9995 - val_loss: 0.1503 - val_accuracy: 0.9974 - lr: 2.4723e-06\n",
      "Epoch 48/50\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.1541 - accuracy: 0.9989 - val_loss: 0.1495 - val_accuracy: 0.9980 - lr: 2.2371e-06\n",
      "Epoch 49/50\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.1518 - accuracy: 0.9995 - val_loss: 0.1491 - val_accuracy: 0.9980 - lr: 2.0242e-06\n",
      "Epoch 50/50\n",
      "195/195 [==============================] - 54s 278ms/step - loss: 0.1521 - accuracy: 0.9992 - val_loss: 0.1479 - val_accuracy: 0.9980 - lr: 1.8316e-06\n"
     ]
    }
   ],
   "source": [
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Model checkpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'efficientnet-model.h5',  # Path where to save the model\n",
    "    save_best_only=True, \n",
    "    monitor='val_loss', \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Combine all callbacks\n",
    "callbacks_list = [\n",
    "    LearningRateScheduler(scheduler),\n",
    "    early_stopping,\n",
    "    model_checkpoint\n",
    "]\n",
    "\n",
    "# Train model with best hyperparameters within strategy scope\n",
    "model = build_efficientnet_model(best_hp)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks_list, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d6635-afc5-4801-bd8d-ee2a54b36af7",
   "metadata": {},
   "source": [
    "### Model Metrics save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f7bfa-97be-440a-8824-d01d6fe85ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Epoch': range(1, len(history.history['loss']) + 1),\n",
    "    'Loss': history.history['loss'],\n",
    "    'Accuracy': history.history['accuracy'],\n",
    "    'Val_Loss': history.history['val_loss'],\n",
    "    'Val_Accuracy': history.history['val_accuracy']\n",
    "})\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "metrics_df.to_csv('efficientnet-metrics.csv', index=False)\n",
    "\n",
    "# Save full model \n",
    "model.save('efficientnet-fullmodel-full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce32ddc-fc22-4a4c-979d-3f1d2c1969fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530f176-a962-4a13-8e07-0a63c1721450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0366229-f867-4321-bc1c-e6d6b219b34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f1a34-420d-4be3-9b6f-8e26e679fa89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f334fc1-5ebb-4ad3-af18-c43927098c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa0eee-0532-4ae7-9fc4-b7cd835d31df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27407d0b-697c-40d0-a866-acc84140c935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bc74f-01d6-4bea-bf22-cf06aab85e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
